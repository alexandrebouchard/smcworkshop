The emerging field of probabilistic programming aims to reduce the technical and cognitive overhead for writing and designing novel probabilistic models, by introducing a specialized programming language as an abstraction barrier between modeling and inference. While we would ideally be able to provide ``automatic" inference for any probabilistic model, this proves severely challenging for models written in sufficiently expressive languages. In this talk I will discuss some of these difficulties, and show how sequential Monte Carlo methods provide a good general-purpose solution for inference in higher-order probabilistic programs. I will also present some recent work which aims to improve sampler efficiency in this setting by automatically learning proposal distributions.